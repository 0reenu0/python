{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469ae803-d824-485a-8a4c-38d377732aa1",
   "metadata": {},
   "source": [
    "### data preprocessing /data cleaning - text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a08519-cd91-40e4-9bc5-872e39d6bbe0",
   "metadata": {},
   "source": [
    "#### change text case to lowercase\n",
    "#### remove special characters and numbers using reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4e70177-83ee-4621-8ace-67933a28c6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Video editing is the process of manipulating and combining video footage to create a cohesive and engaging final product. It involves several key steps, including:\\n11.Importing: Bringing in the video footage from various sources,? such as cameras#, phones%, or other devices.\\n23.Trimming: Cutting out unwanted parts of the video,# such as mistakes or unnecessary footage.\\nArranging: Or'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"\"\"Video editing is the process of manipulating and combining video footage to create a cohesive and engaging final product. It involves several key steps, including:\n",
    "11.Importing: Bringing in the video footage from various sources,? such as cameras#, phones%, or other devices.\n",
    "23.Trimming: Cutting out unwanted parts of the video,# such as mistakes or unnecessary footage.\n",
    "Arranging: Or\"\"\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76a434f8-5d7d-4b33-ad1a-d8c68c3bc8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video editing is the process of manipulating and combining video footage to create a cohesive and engaging final product. it involves several key steps, including:\\n11.importing: bringing in the video footage from various sources, such as cameras, phones, or other devices.\\n23.trimming: cutting out unwanted parts of the video, such as mistakes or unnecessary footage.\\narranging: or'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.lower()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e2b3eed-9e51-416d-8e8a-cc2ad1b811d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18a6dde7-0a15-4943-be91-dbec32f0b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=re.sub(r'\\d+',\"\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9a4cc77-7f3f-422b-bd68-6d0a209b634f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video editing is the process of manipulating and combining video footage to create a cohesive and engaging final product. it involves several key steps, including:\\n.importing: bringing in the video footage from various sources, such as cameras, phones, or other devices.\\n.trimming: cutting out unwanted parts of the video, such as mistakes or unnecessary footage.\\narranging: or'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d13984e-ca3b-4d4b-9023-b4ac0b973dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video editing is the process of manipulating and combining video footage to create a cohesive and engaging final product. it involves several key steps, including.importing: bringing in the video footage from various sources, such as cameras, phones, or other devices.trimming: cutting out unwanted parts of the video, such as mistakes or unnecessary footage.\\narranging: or'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re1=re.sub(r'[^\\w\\s]\\n\\d+',\"\",b)\n",
    "re1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fbd91-ac3b-467a-904f-9928fd708ba1",
   "metadata": {},
   "source": [
    "### Tokenization - using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "388d139f-a825-4dde-9ef4-4fd9a7168972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddbc189-5147-4a8d-942f-0796eb6ccc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\11ree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe225bc-5d20-4299-884e-8544f06172a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "960207fa-5f8d-4e11-99c6-8f5b6c2ab3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=word_tokenize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922c574c-058f-4f4d-af05-7e2fdf5fea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video',\n",
       " 'editing',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'manipulating',\n",
       " 'and',\n",
       " 'combining',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'to',\n",
       " 'create',\n",
       " 'a',\n",
       " 'cohesive',\n",
       " 'and',\n",
       " 'engaging',\n",
       " 'final',\n",
       " 'product',\n",
       " '.',\n",
       " 'it',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'key',\n",
       " 'steps',\n",
       " ',',\n",
       " 'including',\n",
       " ':',\n",
       " '.importing',\n",
       " ':',\n",
       " 'bringing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'from',\n",
       " 'various',\n",
       " 'sources',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'cameras',\n",
       " ',',\n",
       " 'phones',\n",
       " ',',\n",
       " 'or',\n",
       " 'other',\n",
       " 'devices',\n",
       " '.',\n",
       " '.trimming',\n",
       " ':',\n",
       " 'cutting',\n",
       " 'out',\n",
       " 'unwanted',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'video',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'mistakes',\n",
       " 'or',\n",
       " 'unnecessary',\n",
       " 'footage',\n",
       " '.',\n",
       " 'arranging',\n",
       " ':',\n",
       " 'or']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30cbc745-512a-4e36-b136-63290f294e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "012c6ea7-f66d-4024-8eba-245a4c0aa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=wordpunct_tokenize(re1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4860c9ec-481f-404b-b37e-02416f84414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video',\n",
       " 'editing',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'manipulating',\n",
       " 'and',\n",
       " 'combining',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'to',\n",
       " 'create',\n",
       " 'a',\n",
       " 'cohesive',\n",
       " 'and',\n",
       " 'engaging',\n",
       " 'final',\n",
       " 'product',\n",
       " '.',\n",
       " 'it',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'key',\n",
       " 'steps',\n",
       " ',',\n",
       " 'including',\n",
       " '.',\n",
       " 'importing',\n",
       " ':',\n",
       " 'bringing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'from',\n",
       " 'various',\n",
       " 'sources',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'cameras',\n",
       " ',',\n",
       " 'phones',\n",
       " ',',\n",
       " 'or',\n",
       " 'other',\n",
       " 'devices',\n",
       " '.',\n",
       " 'trimming',\n",
       " ':',\n",
       " 'cutting',\n",
       " 'out',\n",
       " 'unwanted',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'video',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'mistakes',\n",
       " 'or',\n",
       " 'unnecessary',\n",
       " 'footage',\n",
       " '.',\n",
       " 'arranging',\n",
       " ':',\n",
       " 'or']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35815ef3-631c-4805-ab5b-0c08df1c7150",
   "metadata": {},
   "source": [
    "### stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4e663bd-5b5f-42de-a788-622905e56c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce6934c4-9bd5-4e52-8e91-7f26dd2ab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "587745db-dae3-4724-98b6-a62298b893b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b90f267d-ca41-4948-9e79-07cd9dd0c503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d5476fc-2531-4e22-b42b-323915298891",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=[x for x in sen if x not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7b5a047-5fda-46af-b9a1-3e2ae5bf74a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video',\n",
       " 'editing',\n",
       " 'process',\n",
       " 'manipulating',\n",
       " 'combining',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'create',\n",
       " 'cohesive',\n",
       " 'engaging',\n",
       " 'final',\n",
       " 'product',\n",
       " '.',\n",
       " 'involves',\n",
       " 'several',\n",
       " 'key',\n",
       " 'steps',\n",
       " ',',\n",
       " 'including',\n",
       " '.',\n",
       " 'importing',\n",
       " ':',\n",
       " 'bringing',\n",
       " 'video',\n",
       " 'footage',\n",
       " 'various',\n",
       " 'sources',\n",
       " ',',\n",
       " 'cameras',\n",
       " ',',\n",
       " 'phones',\n",
       " ',',\n",
       " 'devices',\n",
       " '.',\n",
       " 'trimming',\n",
       " ':',\n",
       " 'cutting',\n",
       " 'unwanted',\n",
       " 'parts',\n",
       " 'video',\n",
       " ',',\n",
       " 'mistakes',\n",
       " 'unnecessary',\n",
       " 'footage',\n",
       " '.',\n",
       " 'arranging',\n",
       " ':']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a81d4a3-ec0e-4716-b098-9821ed5b6ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac17be-a142-41ad-b647-aa7eb7f80a06",
   "metadata": {},
   "source": [
    "### lemmetization and stemming - derived word to root word \n",
    " #### ** run, running, runner\n",
    "#### *** here run is a root word\n",
    "#### *** universe, universal, university - although differet will be stemmed to rot word univers\n",
    "#### this is over - stemming\n",
    "#### *** pharamcies,badly - will not be converted to a root word which is in correc, this is under stemming \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "989aab9c-5460-426c-9203-2b20b4793272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43c63618-b24a-41c3-bac4-a5ff6867383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "990c36af-97e4-42b3-8861-139d8312da96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video',\n",
       " 'edit',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'manipul',\n",
       " 'and',\n",
       " 'combin',\n",
       " 'video',\n",
       " 'footag',\n",
       " 'to',\n",
       " 'creat',\n",
       " 'a',\n",
       " 'cohes',\n",
       " 'and',\n",
       " 'engag',\n",
       " 'final',\n",
       " 'product',\n",
       " '.',\n",
       " 'it',\n",
       " 'involv',\n",
       " 'sever',\n",
       " 'key',\n",
       " 'step',\n",
       " ',',\n",
       " 'includ',\n",
       " '.',\n",
       " 'import',\n",
       " ':',\n",
       " 'bring',\n",
       " 'in',\n",
       " 'the',\n",
       " 'video',\n",
       " 'footag',\n",
       " 'from',\n",
       " 'variou',\n",
       " 'sourc',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'camera',\n",
       " ',',\n",
       " 'phone',\n",
       " ',',\n",
       " 'or',\n",
       " 'other',\n",
       " 'devic',\n",
       " '.',\n",
       " 'trim',\n",
       " ':',\n",
       " 'cut',\n",
       " 'out',\n",
       " 'unwant',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'video',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'mistak',\n",
       " 'or',\n",
       " 'unnecessari',\n",
       " 'footag',\n",
       " '.',\n",
       " 'arrang',\n",
       " ':',\n",
       " 'or']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [ps.stem(x) for x in sen ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45234217-ecb2-4dbe-a420-53e66d77a033",
   "metadata": {},
   "source": [
    "### to overcome the over stemming and unde stemming we use lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0968072-c93f-487d-b597-06fc1d9c2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d7c8259-833a-4633-a83e-7c005776cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86295582-1a2b-4583-be1f-47e7038755bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n",
      "editing\n",
      "is\n",
      "the\n",
      "process\n",
      "of\n",
      "manipulating\n",
      "and\n",
      "combining\n",
      "video\n",
      "footage\n",
      "to\n",
      "create\n",
      "a\n",
      "cohesive\n",
      "and\n",
      "engaging\n",
      "final\n",
      "product\n",
      ".\n",
      "it\n",
      "involves\n",
      "several\n",
      "key\n",
      "step\n",
      ",\n",
      "including\n",
      ".\n",
      "importing\n",
      ":\n",
      "bringing\n",
      "in\n",
      "the\n",
      "video\n",
      "footage\n",
      "from\n",
      "various\n",
      "source\n",
      ",\n",
      "such\n",
      "a\n",
      "camera\n",
      ",\n",
      "phone\n",
      ",\n",
      "or\n",
      "other\n",
      "device\n",
      ".\n",
      "trimming\n",
      ":\n",
      "cutting\n",
      "out\n",
      "unwanted\n",
      "part\n",
      "of\n",
      "the\n",
      "video\n",
      ",\n",
      "such\n",
      "a\n",
      "mistake\n",
      "or\n",
      "unnecessary\n",
      "footage\n",
      ".\n",
      "arranging\n",
      ":\n",
      "or\n"
     ]
    }
   ],
   "source": [
    "for i in sen:\n",
    "    print(ls.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01cbe0b-317d-43f4-9e6b-aa1f9ff6805c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
